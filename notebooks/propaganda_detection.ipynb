{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Propaganda detection is a critical task in natural language processing (NLP) with implications for various domains such as news media analysis, social media monitoring, and misinformation detection. In this project, we aim to detect propaganda in sentences and identify the type of propaganda present, if any. We employ several machine learning and deep learning techniques to tackle these tasks, including Word2Vec with SVM, BERT sequence classification, and TF-IDF with SVM.\n",
    "\n",
    "### Tasks Overview:\n",
    "1. **Propaganda Detection Task**: This task involves determining whether a given sentence contains propaganda or not. \n",
    "   \n",
    "2. **Propaganda Type Detection Task**: In addition to detecting the presence of propaganda, we aim to identify the specific type of propaganda exhibited in a sentence. Common types of propaganda include bandwagon, fear, glittering generalities, and more.\n",
    "\n",
    "### Methods:\n",
    "- **TF-IDF with SVM**: We start with a traditional approach using TF-IDF (Term Frequency-Inverse Document Frequency) for feature extraction, followed by training a Support Vector Machine (SVM) classifier.\n",
    "  \n",
    "- **Word2Vec with SVM**: Word embeddings capture semantic relationships between words, instead of static word counts in TF-IDF that don't add any semantic information. We utilize Word2Vec embeddings to represent sentences and train an SVM classifier on these representations.\n",
    "  \n",
    "- **BERT Sequence Classification**: BERT (Bidirectional Encoder Representations from Transformers) has demonstrated state-of-the-art performance in various NLP tasks. We fine-tune a pre-trained BERT model for sequence classification to detect propaganda and its types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# Natural Language Processing tools\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Machine Learning tools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep Learning and Transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Cleaning\n",
    "\n",
    "- Loaded training and validation datasets containing sentences labeled for propaganda detection.\n",
    "- Checked for null values in both datasets; no null values were found.\n",
    "- Removed duplicates from both datasets to ensure data integrity.\n",
    "- After duplicate removal, the training dataset contained 2405 samples and the validation dataset contained 580 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation datasets\n",
    "propaganda_train = pd.read_csv('../data/raw/propaganda_train.tsv', delimiter='\\t')\n",
    "propaganda_val = pd.read_csv('../data/raw/propaganda_test.tsv', delimiter='\\t')\n",
    "\n",
    "# Preview the daatasets\n",
    "print(\"Training dataset:\", propaganda_train.shape)\n",
    "print(\"Validation dataset:\", propaganda_val.shape)\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\nNull values in training dataset:\")\n",
    "print(propaganda_train.isnull().sum())\n",
    "\n",
    "print(\"\\nNull values in validation dataset:\")\n",
    "print(propaganda_val.isnull().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "propaganda_train.drop_duplicates(inplace=True)\n",
    "propaganda_val.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"\\nDuplicates removed. New dataset shapes:\")\n",
    "print(\"Training dataset:\", propaganda_train.shape)\n",
    "print(\"Validation dataset:\", propaganda_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "- Examine dataset structure, class distribution, and propaganda types.\n",
    "- Analyze length distribution of propaganda spans and sentences.\n",
    "- Inspect sample sentences from each class to understand language usage and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine dataset structure\n",
    "print(\"Training Dataset Structure:\")\n",
    "propaganda_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation Dataset Structure:\")\n",
    "propaganda_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate count and percentage frequency of each propaganda technique in training dataset\n",
    "train_propaganda_counts = propaganda_train['label'].value_counts()\n",
    "train_propaganda_percentages = (train_propaganda_counts / len(propaganda_train)) * 100\n",
    "\n",
    "# Calculate count and percentage frequency of each propaganda technique in validation dataset\n",
    "valid_propaganda_counts = propaganda_val['label'].value_counts()\n",
    "valid_propaganda_percentages = (valid_propaganda_counts / len(propaganda_val)) * 100\n",
    "\n",
    "# Combine counts and percentages into a single dataframe\n",
    "propaganda_table = pd.DataFrame({\n",
    "    'Training Count': train_propaganda_counts,\n",
    "    'Training % Frequency': train_propaganda_percentages,\n",
    "    'Validation Count': valid_propaganda_counts,\n",
    "    'Validation % Frequency': valid_propaganda_percentages\n",
    "})\n",
    "\n",
    "# Display the propaganda table\n",
    "print(\"Propaganda Technique Distribution:\")\n",
    "propaganda_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Propaganda Technique Distribution table provides insights into the distribution of propaganda techniques within the training and validation datasets:\n",
    "\n",
    "- **Training Dataset**:\n",
    "  - The majority of samples are labeled as 'not_propaganda', constituting nearly 49.31% of the training dataset.\n",
    "\n",
    "- **Validation Dataset**:\n",
    "  - The distribution across techniques is generally consistent with the training dataset, with slight variations in percentages.\n",
    "  - 'not_propaganda' remains the dominant category in the validation dataset, comprising approximately 51.90%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length distribution of sentences\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sentence_lengths_train = propaganda_train['tagged_in_context'].apply(lambda x: len(x.split()))\n",
    "sns.histplot(sentence_lengths_train, bins=20, kde=True, stat='density')\n",
    "plt.title('Training Length Distribution of Sentences')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sentence_lengths_val = propaganda_val['tagged_in_context'].apply(lambda x: len(x.split()))\n",
    "sns.histplot(sentence_lengths_val, bins=20, kde=True, stat='density')\n",
    "plt.title('Validation Length Distribution of Sentences')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms illustrate sentence length distributions in word count for the training and validation datasets:\n",
    "\n",
    "1. **Training Dataset**:\n",
    "   - Majority of sentences are short, peaking below 50 words.\n",
    "   - Frequency sharply declines with increasing word count, with few sentences exceeding 200 words.\n",
    "\n",
    "2. **Validation Dataset**:\n",
    "   - Similar distribution to training dataset, peaking at low word counts indicating prevalent short sentences.\n",
    "   - Frequency decreases with higher word counts, mirroring training dataset pattern.\n",
    "\n",
    "**Key Points**:\n",
    "- **Consistency**: Both datasets exhibit similar distributions, ensuring alignment in sentence length.\n",
    "- **Skewness**: Left-skewed distributions suggest a concentration of shorter sentences, potentially impacting model performance.\n",
    "- **Modeling Considerations**: Adaptations may be needed to handle longer sentence inputs effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_snippet(sentence):\n",
    "    match = re.search(r'<BOS>(.*?)<EOS>', sentence)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "# Extract snippets and preprocess labels\n",
    "propaganda_train['snippet'] = propaganda_train['tagged_in_context'].apply(extract_snippet)\n",
    "propaganda_val['snippet'] = propaganda_val['tagged_in_context'].apply(extract_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length distribution of Propaganda Span\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sentence_lengths_train = propaganda_train['snippet'].apply(lambda x: len(x.split()))\n",
    "sns.histplot(sentence_lengths_train, bins=20, kde=True, stat='density')\n",
    "plt.title('Training Length Distribution of Propaganda Span')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sentence_lengths_val = propaganda_val['snippet'].apply(lambda x: len(x.split()))\n",
    "sns.histplot(sentence_lengths_val, bins=20, kde=True, stat='density')\n",
    "plt.title('Validation Length Distribution of Propaganda Span')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sentences from each class\n",
    "print(\"Sample Sentences:\")\n",
    "label_count = 1  # Initialize a counter for the labels\n",
    "for label in propaganda_train['label'].unique():\n",
    "    sample_train = propaganda_train[propaganda_train['label'] == label]['tagged_in_context'].sample(1).values[0]\n",
    "    print(f\"\\n{label_count}. '{label}': {sample_train}\")\n",
    "\n",
    "    label_count += 1  # Increment the label counter after each loop iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Task 1: Propaganda Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Task: TF-IDF with SVM\n",
    "\n",
    "Establishing a baseline for propaganda detection using TF-IDF with SVM to serve as a reference point for evaluating more complex models in subsequent sections. TF-IDF assigns importance scores to words based on how often they appear in a sentence and how rare they are across all sentences. We then use an SVM classifier, which learns to distinguish between propaganda and non-propaganda sentences.\n",
    "  \n",
    "- **Implementation Steps**:\n",
    "  - Clean and prepare the training data.\n",
    "  - Vectorize the text data using TF-IDF.\n",
    "  - Perform hyperparameter tuning for SVM regularization parameter (C) using grid search cross-validation.\n",
    "  - Train an SVM classifier on the TF-IDF vectors.\n",
    "  - Evaluate the model on the validation set and report baseline performance metrics (accuracy, precision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, remove_tags=True):\n",
    "    if remove_tags:\n",
    "        # Directly remove <BOS> and <EOS> tags\n",
    "        text = text.replace('<BOS>', '').replace('<EOS>', '')\n",
    "    else:\n",
    "        # When not removing, replace with placeholders that are unlikely to be altered\n",
    "        text = text.replace('<BOS>', 'BOSPLACEHOLDER').replace('<EOS>', 'EOSPLACEHOLDER')\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and special characters, keeping placeholders intact\n",
    "    tokens = [re.sub(r'[^\\w\\s]', '', token) for token in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Replace placeholders back to original tags if not removed\n",
    "    if not remove_tags:\n",
    "        tokens = ['<BOS>' if token == 'bosplaceholder' else token for token in tokens]\n",
    "        tokens = ['<EOS>' if token == 'eosplaceholder' else token for token in tokens]\n",
    "\n",
    "    # Join tokens back into text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propaganda_train['binary_label'] = np.where(propaganda_train['label'] != 'not_propaganda', 'propaganda', propaganda_train['label'])\n",
    "propaganda_val['binary_label'] = np.where(propaganda_val['label'] != 'not_propaganda', 'propaganda', propaganda_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Clean and preprocess the training data\n",
    "propaganda_train['cleaned_text_tfidf'] = propaganda_train['tagged_in_context'].apply(preprocess_text)\n",
    "\n",
    "# Clean and preprocess the validation data\n",
    "propaganda_val['cleaned_text_tfidf'] = propaganda_val['tagged_in_context'].apply(preprocess_text)\n",
    "\n",
    "# Convert the cleaned training data into TF-IDF vectors\n",
    "X_train = tfidf_vectorizer.fit_transform(propaganda_train['cleaned_text_tfidf'])\n",
    "y_binary_train = propaganda_train['binary_label']\n",
    "\n",
    "# Convert the cleaned validation data into TF-IDF vectors\n",
    "X_valid = tfidf_vectorizer.transform(propaganda_val['cleaned_text_tfidf'])\n",
    "y_binary_valid = propaganda_val['binary_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for C\n",
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Perform grid search cross-validation on the training data\n",
    "grid_search.fit(X_train, y_binary_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train a new SVM classifier with the best hyperparameters\n",
    "best_svm_classifier = SVC(kernel='linear', C=best_params['C'])\n",
    "best_svm_classifier.fit(X_train, y_binary_train)\n",
    "\n",
    "# Predict labels for validation data using the best classifier\n",
    "y_pred_best = best_svm_classifier.predict(X_valid)\n",
    "\n",
    "# Evaluate the best classifier\n",
    "print(\"Best SVM Classifier - Classification Report:\")\n",
    "print(classification_report(y_binary_valid, y_pred_best))\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(best_svm_classifier, '../models/tfidf_svm_model.pkl')\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame(classification_report(y_binary_valid, y_pred_best, output_dict=True))\n",
    "results.to_csv('../results/tfidf_svm_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec with SVM\n",
    "- Train Word2Vec embeddings on the training data.\n",
    "- Convert each sentence into a fixed-length vector representation using Word2Vec embeddings (e.g., averaging word vectors).\n",
    "    - Give weight to the detected propaganda span\n",
    "    - Get the word2vec vector representation for each word in the sentence using the gensim library\n",
    "    - Take the average of the vector representation of all words in the sentence\n",
    "- Perform hyperparameter tuning for SVM regularization parameter (C) using grid search cross-validation.\n",
    "- Train an SVM classifier on the Word2Vec vectors.\n",
    "- Evaluate the model on the validation dataset and report performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtv_preprocess_text(text, weight=3):\n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    in_span = False\n",
    "\n",
    "    for word in words:\n",
    "        if word == '<BOS>':\n",
    "            in_span = True\n",
    "            continue\n",
    "        elif word == '<EOS>':\n",
    "            in_span = False\n",
    "            continue\n",
    "\n",
    "        if in_span:\n",
    "            # Repeat the word `weight` times if it's within the span\n",
    "            new_words.extend([word] * weight)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    \n",
    "    return ' '.join(new_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtv_train_texts = [wtv_preprocess_text(text) for text in propaganda_train['tagged_in_context'].apply(preprocess_text, remove_tags=False)]\n",
    "wtv_val_texts = [wtv_preprocess_text(text) for text in propaganda_val['tagged_in_context'].apply(preprocess_text, remove_tags=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model using skip-gram (sg=1) on the training texts, with a vector size of 300, a context window of 15, and including all words that appear at least once\n",
    "word2vec_model = Word2Vec(sentences=[sentence.split() for sentence in wtv_train_texts], vector_size=300, window=15, min_count=1, workers=4, sg=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence, word2vec_model):\n",
    "    tokens = sentence.split()\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentences to Word2Vec vectors\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_word2vec = label_encoder.fit_transform(y_binary_train)\n",
    "y_valid_word2vec = label_encoder.fit_transform(y_binary_valid)\n",
    "\n",
    "X_train_word2vec = np.array([sentence_to_vector(sentence, word2vec_model) for sentence in wtv_train_texts])\n",
    "X_valid_word2vec = np.array([sentence_to_vector(sentence, word2vec_model) for sentence in wtv_val_texts])\n",
    "\n",
    "# Perform hyperparameter tuning for SVM regularization parameter (C) using grid search cross-validation\n",
    "param_grid = {'C': [1, 10, 15, 10, 20, 30]}\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale')\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=cv_strategy, scoring='accuracy')\n",
    "grid_search.fit(X_train_word2vec, y_train_word2vec)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train SVM classifier on Word2Vec vectors\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale', C=best_params['C'])\n",
    "svm_classifier.fit(X_train_word2vec, y_train_word2vec)\n",
    "\n",
    "\n",
    "# Evaluate the SVM classifier on the validation set\n",
    "y_pred_word2vec = svm_classifier.predict(X_valid_word2vec)\n",
    "print(\"Word2Vec with SVM - Classification Report:\")\n",
    "print(classification_report(y_valid_word2vec, y_pred_word2vec, target_names=label_encoder.classes_))\n",
    "print(\"Best hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(svm_classifier, '../models/word2vec_svm_model.pkl')\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame(classification_report(y_valid_word2vec, y_pred_word2vec, target_names=label_encoder.classes_, output_dict=True))\n",
    "results.to_csv('../results/word2vec_svm_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Sequence Classification\n",
    "- Fine-tune a pre-trained BERT model for sequence classification on the task.\n",
    "- Tokenize the sentences and prepare them for input to BERT.\n",
    "- Perform hyperparameter tuning for BERT fine-tuning parameters (learning rate, batch size, etc.).\n",
    "- Train the BERT model on the training data.\n",
    "- Evaluate the model on the test set.\n",
    "- Report performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropagandaDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            item = {key: self.encodings[key][idx] for key in self.encodings}\n",
    "            item['labels'] = self.labels[idx]\n",
    "            return item\n",
    "        except IndexError as e:\n",
    "            print(f'Error at index: {idx}')\n",
    "            raise e\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(model_name, num_labels, train_labels, val_labels, epochs=3, batch_size=8):\n",
    "\n",
    "    bert_config = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    # Load a cased BERT tokenizer\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Add special tokens\n",
    "    special_tokens_dict = {'additional_special_tokens': ['<BOS>', '<EOS>']}\n",
    "    bert_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    # Resize bert_multi_model embeddings to account for new tokens\n",
    "    bert_config.resize_token_embeddings(len(bert_tokenizer))\n",
    "\n",
    "    def prepare_bert_data(train_texts, val_texts, train_labels, val_labels, tokenizer=bert_tokenizer):\n",
    "        # Tokenize the training and validation data\n",
    "        train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        \n",
    "        # Initialize label encoder based on the type of classification\n",
    "        label_encoder = LabelEncoder()\n",
    "        train_labels = label_encoder.fit_transform(train_labels)\n",
    "        val_labels = label_encoder.transform(val_labels)\n",
    "\n",
    "        # Return a dictionary containing all the processed data\n",
    "        return {\n",
    "            'train_encodings': train_encodings,\n",
    "            'val_encodings': val_encodings,\n",
    "            'train_labels': train_labels,\n",
    "            'val_labels': val_labels\n",
    "        }\n",
    "\n",
    "\n",
    "    prepared_bert_data = prepare_bert_data(list(propaganda_train['tagged_in_context']), list(propaganda_val['tagged_in_context']), list(train_labels), list(val_labels))\n",
    "\n",
    "    train_dataset = PropagandaDataset(prepared_bert_data['train_encodings'], prepared_bert_data['train_labels'])\n",
    "    val_dataset = PropagandaDataset(prepared_bert_data['val_encodings'], prepared_bert_data['val_labels'])\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        save_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\"\n",
    "    )\n",
    "\n",
    "    # Update Trainer setup\n",
    "    trainer = Trainer(\n",
    "        model=bert_config,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,  \n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    return bert_config, trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config, binary_class_bert = train_bert('bert-base-cased', 2, y_binary_train, y_binary_valid, epochs=3, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and tokenizer\n",
    "model_save_path = '../models/bert_binary_class_model'\n",
    "binary_class_bert.save_model(model_save_path)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = binary_class_bert.evaluate()\n",
    "\n",
    "import json\n",
    "# Save evaluation results to a file\n",
    "eval_result_file = '../results/bert_binary_results.json'\n",
    "with open(eval_result_file, 'w') as f:\n",
    "    json.dump(eval_result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Task 2: Propaganda Type Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Task: TF-IDF with SVM\n",
    "- Vectorize the text data using TF-IDF.\n",
    "- Perform hyperparameter tuning for SVM regularization parameter (C) using grid search cross-validation.\n",
    "- Train an SVM classifier on the TF-IDF vectors.\n",
    "- Evaluate the model on the test set.\n",
    "- Report baseline performance metrics (accuracy, precision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Clean and preprocess the training data\n",
    "propaganda_train['cleaned_text_tfidf'] = propaganda_train['tagged_in_context'].apply(preprocess_text)\n",
    "\n",
    "# Clean and preprocess the validation data\n",
    "propaganda_val['cleaned_text_tfidf'] = propaganda_val['tagged_in_context'].apply(preprocess_text)\n",
    "\n",
    "# Convert the cleaned training data into TF-IDF vectors\n",
    "X_train = tfidf_vectorizer.fit_transform(propaganda_train['cleaned_text_tfidf'])\n",
    "y_multi_train = propaganda_train['label']\n",
    "\n",
    "# Convert the cleaned validation data into TF-IDF vectors\n",
    "X_valid = tfidf_vectorizer.transform(propaganda_val['cleaned_text_tfidf'])\n",
    "y_multi_valid = propaganda_val['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "train_vectors_resampled, multi_train_labels_resampled = smote.fit_resample(X_train, y_multi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for C\n",
    "param_grid = {'C': [0.1, 1, 10, 20, 50, 100]}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=cv_strategy, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform grid search cross-validation on the resampled training data\n",
    "grid_search.fit(train_vectors_resampled, multi_train_labels_resampled)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train a new SVM classifier with the best hyperparameters\n",
    "best_svm_classifier = SVC(kernel='linear', C=best_params['C'])\n",
    "best_svm_classifier.fit(train_vectors_resampled, multi_train_labels_resampled)\n",
    "\n",
    "# Predict labels for validation data using the best classifier\n",
    "y_pred_best = best_svm_classifier.predict(X_valid)\n",
    "\n",
    "# Evaluate the best classifier\n",
    "print(\"Best SVM Classifier - Classification Report:\")\n",
    "print(classification_report(y_multi_valid, y_pred_best))\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(best_svm_classifier, '../models/tfidf_svm_multi_model.pkl')\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame(classification_report(y_multi_valid, y_pred_best, output_dict=True))\n",
    "results.to_csv('../results/tfidf_svm_multi_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec with SVM\n",
    "- Train Word2Vec embeddings on the training data.\n",
    "- Convert each sentence into a fixed-length vector representation using Word2Vec embeddings (e.g., averaging word vectors).\n",
    "- Perform hyperparameter tuning for SVM regularization parameter (C) using grid search cross-validation.\n",
    "- Train an SVM classifier on the Word2Vec vectors.\n",
    "- Evaluate the model on the validation dataset and report performance metrics.\n",
    "\n",
    "We'll be considering how well our trained word2vec model can predict the propaganda types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the multi-class labels\n",
    "y_train_word2vec = label_encoder.fit_transform(y_multi_train)\n",
    "y_valid_word2vec = label_encoder.fit_transform(y_multi_valid)\n",
    "\n",
    "# Resample the Word2Vec training vectors using SMOTE\n",
    "X_train_word2vec_resampled, y_train_word2vec_resampled = smote.fit_resample(X_train_word2vec, y_train_word2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform hyperparameter tuning for SVM regularization parameter (C) using grid search cross-validation\n",
    "param_grid = {'C': [0.1, 1, 10, 20, 30, 50, 100, 150]}\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale')\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=cv_strategy, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_word2vec_resampled, y_train_word2vec_resampled)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train SVM classifier on Word2Vec vectors\n",
    "svm_classifier = SVC(kernel='rbf', gamma='scale', C=best_params['C'])\n",
    "svm_classifier.fit(X_train_word2vec_resampled, y_train_word2vec_resampled)\n",
    "\n",
    "# Evaluate the SVM classifier on the validation set\n",
    "y_pred_word2vec = svm_classifier.predict(X_valid_word2vec)\n",
    "print(\"Word2Vec with SVM - Multi Classification Report:\")\n",
    "print(classification_report(y_valid_word2vec, y_pred_word2vec, target_names=label_encoder.classes_))\n",
    "print(\"Best hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(svm_classifier, '../models/word2vec_svm_multi_model.pkl')\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame(classification_report(y_valid_word2vec, y_pred_word2vec, target_names=label_encoder.classes_, output_dict=True))\n",
    "results.to_csv('../results/word2vec_svm_multi_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Sequence Classification\n",
    "- Fine-tune a pre-trained BERT model for sequence classification on the task.\n",
    "- Tokenize the sentences and prepare them for input to BERT.\n",
    "- Perform hyperparameter tuning for BERT fine-tuning parameters (learning rate, batch size, etc.).\n",
    "- Train the BERT model on the training data.\n",
    "- Evaluate the model on the test set.\n",
    "- Report performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config, multi_class_bert_5 = train_bert('bert-base-cased', 9, y_multi_train, y_multi_valid, epochs=5, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = '../models/bert_multi_class_model'\n",
    "multi_class_bert_5.save_model(model_save_path)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = multi_class_bert_5.evaluate()\n",
    "\n",
    "import json\n",
    "# Save evaluation results to a file\n",
    "eval_result_file = '../results/bert_multi_results.json'\n",
    "with open(eval_result_file, 'w') as f:\n",
    "    json.dump(eval_result, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
